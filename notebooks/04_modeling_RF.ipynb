{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import logging\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (plot_roc_curve, classification_report, roc_auc_score, average_precision_score,\n",
    "confusion_matrix, plot_confusion_matrix, plot_precision_recall_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_name': 'template_run',\n",
       " 'test_year': 2020,\n",
       " 'model': 'rf',\n",
       " 'vectorizer': {'type': 'cv',\n",
       "  'ngrams': (1, 3),\n",
       "  'binary': False,\n",
       "  'stopwords': 'english',\n",
       "  'max_df': 0.8,\n",
       "  'min_df': 10},\n",
       " 'grid_search': True,\n",
       " 'hyperparameters': {'n_estimators': [70], 'min_samples_split': [8]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\n",
    "    \"run_name\": \"template_run\",\n",
    "    \"test_year\": 2020,\n",
    "    # Model Type, will support LR, SVC, RandomForest, and NB\n",
    "    'model': 'rf',\n",
    "    # Vectorizer Type (CV, TFIDF)\n",
    "    'vectorizer': {'type': 'cv', \n",
    "                    'ngrams': (1,3),\n",
    "                   'binary': False,\n",
    "                   'stopwords': 'english',\n",
    "                   'max_df': 0.8,\n",
    "                   'min_df': 10\n",
    "                  },\n",
    "    'grid_search': True, # If true, your other hyperparemeters should be in a list.\n",
    "    'hyperparameters': {\n",
    "        # Change these based on your model.\n",
    "        \"n_estimators\": [70],\n",
    "        \"min_samples_split\":[8]\n",
    "        #'max_depth': [1, 2, 4, 8]\n",
    "    }\n",
    "}\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = str(datetime.datetime.now())[:19].replace(\":\",\"-\")\n",
    "logging.basicConfig(filename = f\"../logs/{configs['run_name']}_{ts}.log\", level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215013, 4)\n",
      "(211631, 4)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/combined_clean.csv', sep = \"|\")\n",
    "print(data.shape)\n",
    "logging.info(f\"Date shape before removing duplicates {data.shape}\")\n",
    "data = data.drop_duplicates().reset_index(drop = True)\n",
    "print(data.shape)\n",
    "logging.info(f\"Date shape after removing duplicates {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean'] = data['clean'].astype('U')\n",
    "data['year'] = data['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 177565 records, 10.03% are sarcastic headlines\n",
      "Test has 34066 records, 14.56% are sarcastic headlines\n"
     ]
    }
   ],
   "source": [
    "test_year = configs['test_year']\n",
    "\n",
    "train = data.loc[data['year'] < test_year]\n",
    "test = data.loc[data['year'] == test_year]\n",
    "\n",
    "train_sarcastic_pct = train['is_sarcastic'].mean()*100\n",
    "test_sarcastic_pct = test['is_sarcastic'].mean()*100\n",
    "\n",
    "print(f\"Train has {train.shape[0]} records, {round(train_sarcastic_pct,2)}% are sarcastic headlines\")\n",
    "print(f\"Test has {test.shape[0]} records, {round(test_sarcastic_pct,2)}% are sarcastic headlines\")\n",
    "\n",
    "logging.info(f\"Train has {train.shape[0]} records, {round(train_sarcastic_pct,2)}% are sarcastic headlines\")\n",
    "logging.info(f\"Test has {test.shape[0]} records, {round(test_sarcastic_pct,2)}% are sarcastic headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['clean']\n",
    "y_train = train['is_sarcastic']\n",
    "\n",
    "X_test = test['clean']\n",
    "y_test = test['is_sarcastic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Please adjust the configs or add other data processing steps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure your vectorizer is a valid option or add the functionality.\n",
      "Vectorizer is what converts the text into numerical entries\n",
      "CountVectorizer(max_df=0.8, min_df=10, ngram_range=(1, 3), stop_words='english',\n",
      "                strip_accents='ascii')\n"
     ]
    }
   ],
   "source": [
    "print(\"Please make sure your vectorizer is a valid option or add the functionality.\")\n",
    "print('Vectorizer is what converts the text into numerical entries')\n",
    "\n",
    "if configs['vectorizer']['type'] == \"cv\":\n",
    "    vectorizer = feature_extraction.text.CountVectorizer(\n",
    "                                             lowercase = True,\n",
    "                                             strip_accents = 'ascii',\n",
    "                                             stop_words = configs['vectorizer']['stopwords'],\n",
    "                                             ngram_range = configs['vectorizer']['ngrams'],\n",
    "                                             max_df = configs['vectorizer']['max_df'],\n",
    "                                             min_df = configs['vectorizer']['min_df'],\n",
    "                                             binary = configs['vectorizer']['binary']\n",
    "    )\n",
    "                                                        \n",
    "if configs['vectorizer']['type'] == \"tfidf\":\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "                                             lowercase = True,\n",
    "                                             strip_accents = 'ascii',\n",
    "                                             stop_words = configs['vectorizer']['stopwords'],\n",
    "                                             ngram_range = configs['vectorizer']['ngrams'],\n",
    "                                             max_df = configs['vectorizer']['max_df'],\n",
    "                                             min_df = configs['vectorizer']['min_df'],\n",
    "                                             binary = configs['vectorizer']['binary']\n",
    "    )\n",
    "    \n",
    "assert(vectorizer)\n",
    "vectorizer\n",
    "\n",
    "logging.info(vectorizer)\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Vectorizer and Transform Train & Test\n",
      "CPU times: user 6.11 s, sys: 377 ms, total: 6.49 s\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Fitting Vectorizer and Transform Train & Test\")\n",
    "X_train_transformed =  vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'min_samples_split': [8], 'n_estimators': [70]})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if configs['grid_search']:\n",
    "    if configs['model'] == \"lr\":\n",
    "        model = LogisticRegression()\n",
    "    if configs['model'] == \"rf\":\n",
    "        model = RandomForestClassifier()\n",
    "    if configs['model'] == \"bnb\":\n",
    "        model = BernoulliNB()\n",
    "    if configs['model'] == \"mnb\":\n",
    "        model = MultinomialNB()\n",
    "    if configs['model'] == 'svc':\n",
    "        model = SVC()\n",
    "\n",
    "    grid_search = GridSearchCV(model, configs['hyperparameters'])\n",
    "    \n",
    "logging.info(grid_search)\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be = grid_search.best_estimator_\n",
    "logging.info(\"Best Model:\")\n",
    "logging.info(be)\n",
    "be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "be_preds = be.predict(X_test_transformed)\n",
    "be_probs = be.predict_proba(X_test_transformed)[:,1]\n",
    "\n",
    "print(classification_report(y_test, be_preds))\n",
    "\n",
    "plot_confusion_matrix(be, X_test_transformed, y_test, cmap = plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "plot_roc_curve(be, X_test_transformed, y_test)\n",
    "plt.show()\n",
    "\n",
    "plot_precision_recall_curve(be, X_test_transformed, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_test, be_probs)\n",
    "avg_precision = average_precision_score(y_test, be_probs)\n",
    "cm = confusion_matrix(y_test, be_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'AUC: {auc_score}')\n",
    "logging.info(f'Average Precision: {avg_precision}')\n",
    "logging.info('Confusion Matrix:')\n",
    "logging.info(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
