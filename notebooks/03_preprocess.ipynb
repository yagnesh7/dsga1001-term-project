{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(389504, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/combined_data_v3.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian_length = data[data.source == 'guardian'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Huff = data[data.source == 'Huffington Post']\n",
    "ABC = data[data.source == 'ABC Australia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_sources = data[(data.source != 'Huffington Post') & (data.source != 'ABC Australia')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Huff = Huff.sample(n=guardian_length)\n",
    "ABC = ABC.sample(n=guardian_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181717, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sources = [Huff, ABC, other_sources]\n",
    "data = pd.concat(data_sources)\n",
    "data.reset_index(drop=True, inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143142</th>\n",
       "      <td>atlantic</td>\n",
       "      <td>James Comey's 'Shock and Awe' Testimony</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>Kelly Ripa Will Be Back On Tuesday</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17864</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>Millions Of Kids Might Lose Health Care Becaus...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25220</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>black women are rising – when will our pay?</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65464</th>\n",
       "      <td>ABC Australia</td>\n",
       "      <td>cryptocurrency for selling your dna online</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57366</th>\n",
       "      <td>ABC Australia</td>\n",
       "      <td>nick kyrgios escapes with suspended ban for ci...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-09-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46744</th>\n",
       "      <td>ABC Australia</td>\n",
       "      <td>tafe sa failings laid bare as courses given al...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39127</th>\n",
       "      <td>ABC Australia</td>\n",
       "      <td>cloud over perth royal show wont force date ch...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110331</th>\n",
       "      <td>guardian</td>\n",
       "      <td>Families torn apart: the anatomy of Trump's im...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-06-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22475</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>sia's christmas album title contains an awkwar...</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source                                           headline  \\\n",
       "143142         atlantic            James Comey's 'Shock and Awe' Testimony   \n",
       "10001   Huffington Post                 Kelly Ripa Will Be Back On Tuesday   \n",
       "17864   Huffington Post  Millions Of Kids Might Lose Health Care Becaus...   \n",
       "25220   Huffington Post        black women are rising – when will our pay?   \n",
       "65464     ABC Australia         cryptocurrency for selling your dna online   \n",
       "57366     ABC Australia  nick kyrgios escapes with suspended ban for ci...   \n",
       "46744     ABC Australia  tafe sa failings laid bare as courses given al...   \n",
       "39127     ABC Australia  cloud over perth royal show wont force date ch...   \n",
       "110331         guardian  Families torn apart: the anatomy of Trump's im...   \n",
       "22475   Huffington Post  sia's christmas album title contains an awkwar...   \n",
       "\n",
       "        year        date  is_sarcastic  \n",
       "143142  2017  2017-06-08             0  \n",
       "10001   2016  2016-04-23             0  \n",
       "17864   2017  2017-12-20             0  \n",
       "25220   2019  2019-01-01             0  \n",
       "65464   2018  2018-01-23             0  \n",
       "57366   2019  2019-09-27             0  \n",
       "46744   2018  2018-04-04             0  \n",
       "39127   2017  2017-10-10             0  \n",
       "110331  2018  2018-06-23             0  \n",
       "22475   2019  2019-01-01             0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Steps\n",
    "1. Standardize common abbreviations* (WIP)\n",
    "    1. u.s. --> usa\n",
    "1. Lowercase\n",
    "1. Expand Contractions\n",
    "1. Optional:\n",
    "    1. Remove Source Specific Language\n",
    "    1. Remove Profanity\n",
    "1. Remove Special Characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, replace_dict):\n",
    "    tokens = []\n",
    "    for w in text.split():\n",
    "        word = w\n",
    "        for t in replace_dict.keys():\n",
    "            if w == t:\n",
    "                word = replace_dict[t]\n",
    "        tokens.append(word)\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean'] = data['headline']\n",
    "\n",
    "## Standardize Common Abbreviations\n",
    "translate_dict = {\n",
    "    \"US\": \"USA\",\n",
    "    \"U.S.\": \"USA\",\n",
    "    \"u.s.\": \"USA\",\n",
    "    \"u.s\": \"USA\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data['clean'] = data['clean'].apply(lambda x: replace_words(x, translate_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "data['clean'] = data['clean'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"aren't\": \"are not\",\n",
    "                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n",
    "                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n",
    "                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n",
    "                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n",
    "                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n",
    "                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n",
    "                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n",
    "                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n",
    "                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n",
    "                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n",
    "                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n",
    "                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n",
    "                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n",
    "                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n",
    "                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n",
    "                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n",
    "                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n",
    "                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n",
    "                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n",
    "                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n",
    "                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n",
    "                     \"who's\": \"who is\",\n",
    "                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n",
    "                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n",
    "                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n",
    "                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n",
    "                     \"you've\": \"you have\"}\n",
    "\n",
    "\n",
    "\n",
    "data['clean'] = data['clean'].apply(lambda x: replace_words(x, contractions_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'french president francois hollande says he will not seek re-election'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example should read: who is afraid\n",
    "data['clean'][77627]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Special Characters\n",
    "data['clean'] = data['clean'].apply(lambda x: re.sub('[^A-Za-z0-9 ]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         saudi arabias public cinema ban lifts with a s...\n",
       "1         maryland police charge 3 church leaders with p...\n",
       "2         manatees no longer facing extinction but there...\n",
       "3         usa lashed as main threat to environment at un...\n",
       "4         olympian proudly says black girls rock as she ...\n",
       "                                ...                        \n",
       "181712    overworked gamer wishes he could just stay hom...\n",
       "181713    how king henry viii became the worlds first ga...\n",
       "181714    ring fit user hates how crowded adventure gets...\n",
       "181715    gamer postpones new years resolution until q3 ...\n",
       "181716    netflix announces its losing the audio portion...\n",
       "Name: clean, Length: 181717, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['source', 'year', 'clean', 'is_sarcastic']].to_csv('../data/combined_clean.csv', index = False, sep = \"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['source', 'year', 'clean', 'is_sarcastic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>year</th>\n",
       "      <th>clean</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>2018</td>\n",
       "      <td>saudi arabias public cinema ban lifts with a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>2018</td>\n",
       "      <td>maryland police charge 3 church leaders with p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>2016</td>\n",
       "      <td>manatees no longer facing extinction but there...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>2017</td>\n",
       "      <td>usa lashed as main threat to environment at un...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>2016</td>\n",
       "      <td>olympian proudly says black girls rock as she ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181712</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>2020</td>\n",
       "      <td>overworked gamer wishes he could just stay hom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181713</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>2020</td>\n",
       "      <td>how king henry viii became the worlds first ga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181714</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>2020</td>\n",
       "      <td>ring fit user hates how crowded adventure gets...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181715</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>2020</td>\n",
       "      <td>gamer postpones new years resolution until q3 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181716</th>\n",
       "      <td>Hard Times</td>\n",
       "      <td>2020</td>\n",
       "      <td>netflix announces its losing the audio portion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181717 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source  year  \\\n",
       "0       Huffington Post  2018   \n",
       "1       Huffington Post  2018   \n",
       "2       Huffington Post  2016   \n",
       "3       Huffington Post  2017   \n",
       "4       Huffington Post  2016   \n",
       "...                 ...   ...   \n",
       "181712       Hard Times  2020   \n",
       "181713       Hard Times  2020   \n",
       "181714       Hard Times  2020   \n",
       "181715       Hard Times  2020   \n",
       "181716       Hard Times  2020   \n",
       "\n",
       "                                                    clean  is_sarcastic  \n",
       "0       saudi arabias public cinema ban lifts with a s...             0  \n",
       "1       maryland police charge 3 church leaders with p...             0  \n",
       "2       manatees no longer facing extinction but there...             0  \n",
       "3       usa lashed as main threat to environment at un...             0  \n",
       "4       olympian proudly says black girls rock as she ...             0  \n",
       "...                                                   ...           ...  \n",
       "181712  overworked gamer wishes he could just stay hom...             1  \n",
       "181713  how king henry viii became the worlds first ga...             1  \n",
       "181714  ring fit user hates how crowded adventure gets...             1  \n",
       "181715  gamer postpones new years resolution until q3 ...             1  \n",
       "181716  netflix announces its losing the audio portion...             1  \n",
       "\n",
       "[181717 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
