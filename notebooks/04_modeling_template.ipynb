{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'lr',\n",
       " 'vectorizer': {'type': 'cv',\n",
       "  'ngrams': (1, 3),\n",
       "  'binary': False,\n",
       "  'stopwords': 'english',\n",
       "  'max_df_prop': 0.8,\n",
       "  'min_df_prop': 0.01},\n",
       " 'hyperparameters': {'grid_search': True,\n",
       "  'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "  'solver': ['lbfgs'],\n",
       "  'penalty': ['l2'],\n",
       "  'max_iter': [100]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\n",
    "    # Model Type, will support LR, SVC, RandomForest, and NB\n",
    "    'model': 'lr',\n",
    "    # Vectorizer Type (CV, TFIDF)\n",
    "    'vectorizer': {'type': 'cv', \n",
    "                    'ngrams': (1,3),\n",
    "                   'binary': False,\n",
    "                   'stopwords': 'english',\n",
    "                   'max_df_prop': 0.8,\n",
    "                   'min_df_prop': 0.01\n",
    "                  },\n",
    "    'hyperparameters': {\n",
    "        # Change these the most based on your model.\n",
    "        \"grid_search\": True, # If true, your other hyperparemeters should be in a list.\n",
    "        \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "        \"solver\": [\"lbfgs\"],\n",
    "        \"penalty\": [\"l2\"],\n",
    "        \"max_iter\": [100]\n",
    "    }\n",
    "}\n",
    "\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import plot_roc_curve, classification_report,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/combined_clean.csv', sep = \"|\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
